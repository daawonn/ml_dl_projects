{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝을 이용한 언어 감지 서비스 구축\n",
    "\n",
    "### 1. 연구 목표 설정\n",
    "\n",
    "- 유사서비스 : 파파고, 구글 번역\n",
    "- 개요\n",
    "  - 번역 서비스 중 언어 감지 파트는 머신러닝의 지도학습법 중 분류를 사용하겠다\n",
    "  - 알파벳을 사용하는 영어권에서는 알파벳 언어별로 알파벳의 사용 빈도가 다르다\n",
    "- 조건\n",
    "   - 비 영어권은 개별 방법론(완성형(utf-8), 조합형(euc-kr) 코드를 이용하여 판단)\n",
    "   - 임시값(100byte) 이내 문자열을 배제, 임시값의 임계값은 변경될 수 있다\n",
    "   - 번역서비스는 딥러닝의 RNN 을 활용하여 처리하는데 여기서는 배제, 단 파파고 API를 활용하여 유사하게 구현\n",
    "   - 서비스가 오픈하고 데이터가 축적되면 모델을 갱신(언어는 진화하니까) \n",
    "       모델을 다시 학습하고 교체를 진행하는데 원활하게 수행되게끔 처리 ( 전략이 필요 ) 일단 여기서는 데이터 축적."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|No|단계|내용|\n",
    "|:---:|:---|:---|\n",
    "|1|연구 목표 설정|- 웹서비스<br>- 사용자가 입력한 텍스트를 예측하여 어떤 언어인지 판독한다(영어권.알파벳 사용국)<br>- 머신러닝의 지도학습-분류를 사용하겠다<br>- 파이프라인구축, 하이퍼파라미터튜닝을 이용한 최적화 부분은 제외<br>- 정량적인 목표치는 생략(평가배제)<br>- 임시값(100byte) 이내 문자열을 배제<br>- 논문을 통한 주장의 근거를 체크 |\n",
    "|2|데이터 획득/수집|- 실전:다양한 텍스트를 수집, 위키피디아, 법률, 소설등등<br>- 구현:제공데이터를 사용(법령/대본/소설등)|\n",
    "|3|데이터 준비/통찰/전처리|- 알파벳을 제외한 모든 문자 제거(전처리,정규식)<br>- 텍스트를 알파벳의 출현 빈도로 계산한다(문자계산, 데이터의 수치화)<br>- 데이터는 훈련데이터(훈련:50,검증:25)와 테스트데이터(25)로 나눈다 (훈련:테스트=75:25 황금비율 절대적이진 않음)|\n",
    "|4|데이터 탐색/통찰/시각화|- 논문의 주장을 증명<br>- 영어권 언어별로 알파벳 출현 빈도가 다르다는 명제를 증명/확인<br>- EDA 분석(시각화)를 이용하여 확인, 선형차트, 바차트 등을 활용|\n",
    "|5|데이터 모델링 및 구축|- 알고리즘 선정<br>- 학습데이터/테스트데이터 준비<br>- 학습<br>- 예측<br>- 성능평가(학습법,하위 카테고리 까지 검토 평가)<br>- 파이프라인구축을 통하여 알고리즘 체인을 적용, 최적의 알고리즘 조합을 찾는다<br>- 연구목표에 도착할때까지 반복|\n",
    "|6|시스템 통합|- 모델 덤프(학습된 알고리즘을 파일로 덤프)<br>- 웹서비스 구축(Flask 간단하게 구성)<br>- 서비스구축<br>- 모델의 업그레이드를 위한 시스템 추가 <br>- 선순환구조를 위한 번역 요청 데이터의 로그 처리 -> 배치학습,온라인학습 등으로 연결되어 완성|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 획득\n",
    "\n",
    "- 실전:다양한 텍스트를 수집, 위키피디아, 법률, 소설등등\n",
    "  - 라이브러리 : request, bs4 <- lv3\n",
    "  - 사이트 : https://언어코드.wikipedia.org/wiki/검색어\n",
    "       - 예) https://en.wikipedia.org/wiki/Bong_Joon-ho\n",
    "- 구현:제공데이터를 사용(법령/대본/소설등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 가져오기\n",
    "import urllib.request as req\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/Bong_Joon-ho'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 획득 사이트\n",
    "target_site = 'https://{na_code}.wikipedia.org/wiki/{keyword}'.format( na_code='en', keyword='Bong_Joon-ho' )\n",
    "target_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요청 및 SOUP 생성(DOM 트리)\n",
    "# html5lib 파서 사용 이유 : 대량의 html을 파싱하기 위해 안전성 고려\n",
    "soup = BeautifulSoup(req.urlopen(target_site),'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, list)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 추출\n",
    "# css selector : #mw-content-text p\n",
    "tmp = soup.select('#mw-content-text p')\n",
    "len(tmp), type(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22,\n",
       " ['\\n',\n",
       "  'Bong Joon-ho (Korean:\\xa0봉준호, Korean pronunciation:\\xa0[poːŋ tɕuːnho → poːŋdʑunɦo]; born September 14, 1969) is a South Korean film director and screenwriter. He garnered international acclaim for his second feature film Memories of Murder (2003), before achieving commercial success with his subsequent films The Host (2006) and Snowpiercer (2013), both of which are among the highest-grossing films of all time in South Korea.[1] \\n'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p 밑에 있는 모든 텍스트를 리스트에 모아 둔다 => 멤버수가 22개\n",
    "# 리스트 생성\n",
    "texts = []  #list() 와 [] 는 약간의 차이가 있음\n",
    "\n",
    "for p in tmp :\n",
    "    # 멤버 추가\n",
    "    # append 와 extend 의 차이 => 동료와 자식의 차이\n",
    "    texts.append(p.text)\n",
    "    \n",
    "len(texts),texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, [' Media related to Bong Joon-ho at Wikimedia Commons\\n'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리스트 내포\n",
    "texts = [p.text for p in tmp]\n",
    "len(texts), texts[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13245,\n",
       " '\\nBong Joon-ho (Korean:\\xa0봉준호, Korean pronunciation:\\xa0[poːŋ tɕuːnho → poːŋdʑunɦo]; born September 14, 19')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 수집한 데이터를 한개의 텍스트 덩어리로 통합\n",
    "str_txt=''.join(texts)\n",
    "len(str_txt), str_txt[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규식을 활용하여 알파벳만 남긴다\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = re.compile('[^a-zA-Z]*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bongjoonhokoreankoreanpronunciationpotunhopodunobornseptemberisasouthkoreanfilmdirectorandscreenwriterhegarneredinternationalacclaimforhissecondfeaturefilmmemoriesofmurderbeforeachievingcommercialsuccesswithhissubsequentfilmsthehostandsnowpiercerbothofwhichareamongthehighestgrossingfilmsofalltimeinsouthkoreatwoofhisfilmshavescreenedincompetitionatthecannesfilmfestivalokjawhichpremieredatthecannesfilmfestivalandparasitewhichwonthepalmedoratthecannesfilmfestivalhebecamethefirstkoreandirectortowinthepalmedorparasitealsowonbestforeignlanguagefilmatthethgoldenglobeawardswithbongnominatedforbestdirectorandbestscreenplayforhisworkinmetacriticrankedbongsixteenthonitslistofthebestfilmdirectorsofthestcenturyhisfilmsfeaturetimelysocialthemesgenremixingblackhumorandsuddenmoodshiftsbongjoonhowasbornindaeguinanddecidedtobecomeafilmmakerwhileinmiddleschoolbongjoonhohadahighlyintellectualupbringinghisfatherbongsanggyunisagraphicdesignerandhismaternalgrandfatherparktaewonwasanotedauthorfamousforadayinthelifeofnovelistgubohisolderbrotherjoonsooisanenglishliteratureprofessornowteachinginseoulnationaluniversityandhisoldersisterjeeheeisafashiondesignerdespitehispassionforfilmhedidnotenrollforatheatermajorinuniversityduetohisparentsdisagreementhemajoredinsociologyinyonseiuniversityinthelatesandwasamemberofthefilmclubtherehewasthenafanofedwardyanghouhsiaohsienandshoheiimamuraintheearlyshecompletedatwoyearprogramatthekoreanacademyoffilmartswhiletherehemademanymmshortfilmshisgraduationfilmsmemorywithintheframeandincoherencewereinvitedtoscreenatthevancouverandhongkonginternationalfilmfestivalshealsocollaboratedonseveralworkswithhisclassmatesmostnotablyascinematographeronthehighlyacclaimedshortimaginedirectedbyhisfriendjangjoonhwanasidefromcinematographyonhurjaeyoungsshortahatbongwasalsolightingdirectoronanearlyshortsoundsfromheavenandearthbychoiequanandtheloveofagrapeseedaftergraduatinghespentthenextfiveyearscontributinginvariouscapacitiestoworksbyotherdirectorshereceivedapartialscreenplaycreditontheomnibusfilmsevenreasonswhybeerisbetterthanaloverbothscreenplayandassistantdirectorcreditsonparkkiyongsdebutmotelcactusandisoneoffourwritersalongwithjangjoonhwancreditedforthescreenplayofphantomthesubmarineshortlyafterwardsbongbeganshootinghisfirstfeaturebarkingdogsneverbiteunderproducerchaseungjaewhohadoverseentheproductionofbothmotelcactusandphantomthesubmarinethefilmaboutalowrankinguniversitylecturerwhoabductsaneighborsdogwasshotinthesameapartmentcomplexwherebonghadlivedaftergettingmarriedalthoughnowrememberedfondlyatthetimeofitsreleaseinfebruaryitdidnotstirupmuchinterestamongaudiencesresponsefromcriticswaspositivebutslightlymutednonethelessthefilmwasinvitedtothecompetitionsectionofspainsprestigioussansebastianinternationalfilmfestivalanditwouldgoontowinawardsatslamdanceandhongkongslowlybuildinginternationalwordofmouthalsohelpedthefilmfinanciallyovertwoyearsafteritslocalreleasethefilmreacheditsfinancialbreakevenpointduetosalestooverseasterritoriesbongssecondfilmmemoriesofmurderamuchlargerscaleprojectwasadaptedfromapopularstageplaycenteredonareallifeserialkillerwhoterrorizedaruraltowninthesandwasnevercaughtalthoughsouthkoreanauthoritiesannouncedinthattheyhaveasuspectidentifiedthroughdnaevidenceproductionofthefilmwasalongandarduousprocessthefilmsetalocalrecordforthesheernumberoflocationsitutilizedbutwiththeweatherprovidingunexpectedhelpwithsomestunningskyscapesthefilmwrappedwithoutmajorproblemsitwasreleasedinaprilandprovedanimmediatecriticalandpopularsuccessenthusiasticwordofmouthdrovethefilmtoselloverfivemillionticketsrescuingchaseungjaesproductioncompanysidusfromnearbankruptcyandastringoflocalhonorsfollowedincludingbestpicturebestdirectorbestactorforsongkanghoandbestlightingprizesatthegrandbellawardsalthoughpassedoverbythecannesandvenicefilmfestivalsthefilmeventuallyreceiveditsinternationalpremiereagainatsansebastianwhereitpickedupthreeawardsincludingbestdirectorthefilmalsoreceivedanunusuallystrongcriticalreceptiononitsreleaseinforeignterritoriessuchasfranceandtheusfollowingthisbongtooksometimetocontributeshortfilmstotwoomnibusprojectsinfluenzaisadisturbingminuteworkactedoutentirelyinfrontofrealcctvcamerasstationedthroughoutseoulthefilmwhichchartsfromadistancequiteliterallyadesperatemansturntoviolentcrimeoverthespaceoffiveyearswascommissionedbythejeonjuinternationalfilmfestivaltogetherwithworksbyjapanesedirectorsogoishiiandhongkongbasedyulikwaitwentidentitymeanwhileisapartomnibusfilmmadebyalumniofthekoreanacademyoffilmartsontheoccasionoftheschoolsthanniversarybongscontributionissinkriseawhimsicalworksetalongsidethehanriverthatcanbeseenasawarmupforthedirectorsthirdfeaturethehostmarkedastepupinscaleinbongscareerandindeedforthekoreanfilmindustryasawholethebigbudgetmillionworkcenteredonafictionalmonsterthatrisesupoutofthehanrivertowreakhavoconthepeopleofseoulandononefamilyinparticularfeaturingmanyoftheactorswhohadappearedinhispreviousfilmsthefilmwasthefocusofstrongaudienceinterestevenbeforeitstartedshootingbutmanydoubtswereraisedaboutwhetherakoreanproductioncouldrisetothechallengeofcreatingafullfledgedbelievabledigitalmonsterafterinitiallycontactingnewzealandswetadigitalthecompanyresponsibleforthecgiinthelordoftheringsschedulingconflictsledbongtosanfranciscobasedtheorphanagewhotookonthemajorityoftheeffectsworkafterrushingtomeetdeadlinesthefilmreceivedarapturouspremiereinthedirectorsfortnightsectionofthecannesfilmfestivalalthoughlocalaudienceswereslightlymorecriticalofthehostthanattendeesatcannesthefilmwasnonethelessamajorsummerhitwiththeaterownerscallingformoreandmoreprintsthefilmenjoyedsouthkoreaswidestreleaseeveronoverathirdofthenationsscreensandsetanewboxofficerecordwithmillionticketssoldthehostwasquicklysoldaroundtheworldandusstudiouniversalboughttheremakerightsinbongalongwithmichelgondryandfrenchdirectorleoscaraxdirectedasegmentoftokyoatriptychfeaturetellingthreeseparatetalesofthecitybongssegmentisaboutamanwhohaslivedforadecadeasahikikomorithetermusedinjapanforpeopleunabletoadjusttosocietywhodontleavetheirhomesandwhathappenswhenhefallsinlovewithapizzadeliverygirlbongsfourthfeaturefilmmotheristhestoryofadotingmotherwhostrugglestosaveherdisabledsonfromamurderaccusationitpremieredintheuncertainregardsectionatcannesfilmfestivaltomuchacclaimparticularlyforactresskimhyejamotherrepeateditscriticalsuccesslocallyandintheinternationalfilmfestivalcircuitthefilmappearedonmanyfilmcriticsbestoflistsofinbongcontributedtoasenseofhomeananthologyoffilmseachminutessecondsindurationaddressingthethemeofhomethefilmsweremadebyfilmmakersinresponsetothedevastatingearthquakeandtsunamiwhichhitthetohokuregionofjapanonmarchthefilmscreenedonthefirstanniversaryofthedisasterinbongsshortfilmikiateenagegirlfindsatoddlerseeminglydeadonabeachthatsameyearbongservedasajurymemberforthethsundancefilmfestivalhewasalsotheheadofthejuryforthecamradorsectionofthecannesfilmfestivalandtheedinburghinternationalfilmfestivalinbongreleasedhisfirstenglishlanguagefilmsnowpiercerbasedonthegraphicnovelletransperceneigebyjeanmarcrochetteandjacqueslobandsetlargelyonafuturistictrainwherethoseonboardareseparatedaccordingtotheirsocialstatussnowpiercerpremieredatthetimessquareonjulyinseoulsouthkoreabeforescreeningatthedeauvilleamericanfilmfestivalastheclosingfilmonseptembertheberlininternationalfilmfestivalasthepartofberlinsforumsidebaronfebruaryopeningthelosangelesfilmfestivalonjuneandtheedinburghinternationalfilmfestivalonjuneuponreleaseincinemasthefilmwasmetwithnearuniversalpraiseandstrongticketsalesbothinsouthkoreaandabroadasofaprilupdateitisthetenthhighestgrossingdomesticfilminsouthkoreawithadmissionsthefilmholdsthedomesticrecordforthefastestmoviedomesticandforeigntoreachfourmillionadmissionswhichitachievedinitsfifthdayafterpremiereandanotherrecordforthehighestweekendfigurefromfridaytosundayforakoreanfilmwithmillionviewersinadditiontoreceivingseveralawardsandnominationssnowpiercerappearedonseveralcriticslistsofthetenbestfilmsofinbongsnextfilmokjawasannouncedonaprilscreenwriterjonronsonannouncedonhistwitteraccountthathewaswritingtheseconddraftofbongsscreenplayforthefilmdariuskhondjijoinedthefilmascinematographerinfebruaryfilmingfortheprojectbeganinaprilinbongpremieredokjaatthecannesfilmfestivalwhereitcompetedforthepalmedorandsparkedcontroversyduetoitbeingproducedbynetflixthefilmwasmetwithboosmixedwithapplauseduringapressscreeningatthefilmfestivaloncewhenthenetflixlogoappearedonscreenandagainduringatechnicalglitchwhichgotthemovieprojectedinanincorrectaspectratioforitsfirstsevenminutesthefestivallaterissuedanapologytothefilmmakershoweverdespitethestudiosnegativeresponsethefilmitselfreceivedafourminutestandingovationfollowingitsactualpremierethefilmwaslaterreleasedonnetflixonjuneandreceivedpositivereviewsonthefilmreviewaggregatorwebsiterottentomatoesthefilmhasanapprovalratingofbasedonreviewswithaweightedaverageofthesitescriticalconsensusreadsokjaseesbongjoonhocontinuingtocreatedefiantlyeclecticentertainmentandstillhittingmorethanenoughofhisnarrativetargetsinthemidstofatrickytonaljugglingactonmetacriticthefilmhasascoreofoutofbasedoncriticsindicatinggenerallyfavorablereviewsnewyorktimescriticaoscottwroteokjaisamiracleofimaginationandtechniqueandokjainsistswithabundantmischiefandabsolutesinceritythatshepossessesasoulinbongdirectedthefullkoreanlanguagefilmparasiteacomedythrilleraboutapoorfamilythatinsinuatesitselfintoawealthyhouseholdthefilmpremieredatthecannesfilmfestivalwhereitwonthepalmedorbecomingthefirstkoreanfilmtoreceivetheawardandthefirstfilmtodosowithaunanimousvotesincesblueisthewarmestcolouritwassubsequentlyselectedasthesouthkoreanentryforbestinternationalfeaturefilmatthendacademyawardsthefilmalsowonthesydneyfilmprizeatthesydneyfilmfestivalatsydneyparasitewasincompetitionalongsideotherfeaturesfromcountriessuchasnorthmacedoniabrazilandspainandaustralianentrantsmirrahfoulkessjudypunchandbenlawrencesheartsandbonesparasitewasreleasedinsouthkoreabycjentertainmentonmayandintherestoftheworldbyneoninlateitreceivedwidespreadcriticalacclaimandearnedmillionattheworldwideboxofficebecomingbongshighestgrossingreleaseforparasitebongwasnominatedforbestdirectorandbestscreenplayatthethgoldenglobeawardswiththefilmitselfwinningbestforeignlanguagefilmfilmographysourceskmdbandimdbmediarelatedtobongjoonhoatwikimediacommons'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = p.sub('',str_txt)\n",
    "# 전부 소문자로 처리\n",
    "tmp.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 준비\n",
    "- 알파벳을 제외한 모든 문자 제거(전처리,정규식)\n",
    "  - 편의상 앞단계에서 같이 병행 처리했다\n",
    "  - 제공 데이터에서는 여기서 실제로 처리하겠다\n",
    "- 텍스트를 알파벳의 출현 빈도로 계산한다(문자계산, 데이터의 수치화)\n",
    "- 데이터는 훈련데이터(훈련:50,검증:25)와 테스트데이터(25)로 나눈다 (훈련:테스트=75:25 황금비율 절대적이진 않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 다 읽어 들인다 => 파일목록이 필요하다.\n",
    "# glob 특정 패턴을 부여해서 특정 위치의 파일 목록을 가져온다 => 외장함수\n",
    "import os.path, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, list, ['./data/train\\\\en-1.txt', './data/train\\\\en-2.txt'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = glob.glob('./data/train/*.txt')\n",
    "len(file_list), type(file_list), file_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/train\\\\en-1.txt'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일을 읽어서 알파벳 별 빈도를 계산, 그런 데이터가 en 혹은 fr 등 이 데이터가 어떤 언어인지(레이블, 정답)까지 데이터화 한다\n",
    "# 1. 파일명 획득\n",
    "fName = file_list[0]\n",
    "fName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en-1.txt'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 파일명 획득\n",
    "name = os.path.basename(fName)\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 파일명에는 정답(레이블)이 들어있다. 이것을 추출\n",
    "# 확장성을 고려하여 정규식으로 처리\n",
    "p = re.compile('^[a-z]{2,}')\n",
    "if p.match(name):\n",
    "    lang = p.match(name).group()\n",
    "else :\n",
    "    print('일치하지 않음')\n",
    "lang    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4595"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 알파벳 빈도 계산\n",
    "# 4-1. 파일을 읽는다\n",
    "file = open('./data/train/en-1.txt','r',encoding='utf-8')\n",
    "# print(file)\n",
    "train_file = file.readlines()\n",
    "# print(train_file)\n",
    "# 4-2. 알파벳만 남긴다(정규식으로 전처리)\n",
    "str_txt=''.join(train_file)\n",
    "p = re.compile('[^a-zA-Z]*')\n",
    "tmp = p.sub('',str_txt)\n",
    "type(tmp)\n",
    "# # 4-3. 소문자로 처리\n",
    "tmp_1 = tmp.lower()\n",
    "tmp_1\n",
    "# 4-4. 알파벳 별로 카운트 계산 = > 효율적인 로직, 방법으로 만들기\n",
    "alpha_count = 0\n",
    "\n",
    "for line in tmp_1:\n",
    "    alpha_count += [c.isalpha() for c in line].count(True)\n",
    "alpha_count    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_count = 0\n",
    "\n",
    "for line in open('./data/train/en-1.txt','r',encoding='utf-8'):\n",
    "    alpha_count += [c.isalpha() for c in line].count(True)\n",
    "alpha_count   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "result = Counter(tmp_1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob('./data/train/*.txt')\n",
    "\n",
    "all_list = []\n",
    "\n",
    "for list in file_list:\n",
    "    f = open(list,'r',encoding='utf-8')    \n",
    "    all_list.extend(f.readlines())\n",
    "    \n",
    "str_txt=''.join(all_list)    \n",
    "\n",
    "p = re.compile('[^a-zA-Z]*')\n",
    "\n",
    "tmp = p.sub('',str_txt)\n",
    "\n",
    "tmp_1 = tmp.lower()\n",
    "\n",
    "result = Counter(tmp_1)\n",
    "\n",
    "print(result)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4595, 'th', str)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 알파벳 빈도 계산\n",
    "# with : 입출력(I/O)계열에서 사용, close를 자동으로 처리\n",
    "with open(fName, 'r', encoding = 'utf-8') as f:\n",
    "    # 4-1. 파일을 읽는다.\n",
    "#     print(f.read())\n",
    "    # 4-3. 소문자로 처리\n",
    "    text = f.read().lower()\n",
    "\n",
    "    # 4-2. 알파벳만 남긴다(정규식으로 전처리)\n",
    "    #정규식을 필요에 의해서 보정이 더 가능\n",
    "    p =re.compile('[^a-z]')   # * 있으나 없으나 똑같음\n",
    "    text = p.sub('',text)\n",
    "#     print(text)\n",
    "    \n",
    "# #     pass\n",
    "\n",
    "len(text), text[:2], type(text)\n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[349, 59, 210, 212, 484, 72, 88, 201, 340, 8, 25, 247, 121, 356, 412, 76, 0, 357, 282, 370, 119, 45, 65, 3, 92, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 4595, 4595, 0, 484)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4-4. 알파벳 별로 카운트 계산=>효율적인 로직, 방법이 필요\n",
    "# 알파벳 한개 한개를 카운트해서 담을 그릇(공간) -> 순서가 존재\n",
    "# 알파벳은 개수가? 26개\n",
    "counts = [ 0 for n in range(26) ]\n",
    "# a=>0, b=>1, ... z=>25 알파벳순으로 리스트의 맴버 인덱스를 적용\n",
    "# -> 한문자씩 읽는다\n",
    "# ord('a') = a라는 문자열의 아스키값을 리턴 => 97\n",
    "# \"https://namu.wiki/w/아스키 코드\" 참조\n",
    "for word in text:\n",
    "    #print('문자열 한개', word )\n",
    "    #print('해당 문자열의 카운트 개수를 담고 있는 리스트상의위치', ord(word)-ord('a'))\n",
    "    #print('해당 문자열의 카운트수', counts[ord(word)-ord('a')]  )\n",
    "    # 구현\n",
    "    counts[ord(word)-ord('a')] += 1\n",
    "    #break\n",
    "# 원본, 리스트의 맴버들의 카운트 총합 == 문자열의수\n",
    "print(counts), sum(counts), len(text), min(counts), max(counts)\n",
    "# 카운트 데이터를 들여다 보니 값의 편차가 크다 => 학습효과가 저하 => 값을 특정구간으로 재배치 => 정규화(nomarlize) 0~1 사이로\n",
    "# a빈도/총빈도 .... z빈도/총빈도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-16070992c119>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 연속 데이터 타입의 멤버들을 하나씩 접근해서 작업을 한다 => map 함수 사용\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtotal_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "# 정규화 수행하기 \n",
    "# 연속 데이터 타입의 멤버들을 하나씩 접근해서 작업을 한다 => map 함수 사용\n",
    "total_count = sum(counts)\n",
    "freq = list( map( lambda x:x/total_count, counts))\n",
    "freq[:2], len(freq), sum(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-bfcc14866a84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetect_trans_lang_freq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-67-bfcc14866a84>\u001b[0m in \u001b[0;36mdetect_trans_lang_freq\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# 빈도수는 값이 너무 퍼져있기때문에 0~1 사이로 정규화 시켜준다. => 학습효과가 뛰어나진다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mtotal_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mfreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtotal_count\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "# 파일 경로를 넣으면 정답(국가코드), 알파벳빈도 를 계산한 데이터를 리턴하는 함수 구현\n",
    "def detect_trans_lang_freq(file_path):\n",
    "    # 파일명 획득\n",
    "    name = os.path.basename(file_path)\n",
    "    # 정답, 국가코드 획득\n",
    "    p = re.compile('^[a-z]{2,}')\n",
    "    if p.match(name):\n",
    "        lang = p.match(name).group()\n",
    "    else :\n",
    "        return None, None\n",
    "    #---------------------------------\n",
    "    with open( file_path, 'r', encoding='utf-8' ) as f:  # 파일오픈\n",
    "        text = f.read().lower()             # 전부 읽어서 소문자로 리턴\n",
    "        p    = re.compile('[^a-z]')         # 정규식(알파벳소문자만제외)\n",
    "        text = p.sub( '' , text )           # 소문자만 남는다\n",
    "        counts = [ 0 for n in range(26) ]  # 알파벳별 카운트를 담을 공간(리스트)\n",
    "        limit_a = ord('a')                  # 매번 반복해서 작업하니까 그냥 최초 한번 변수로 받아서 계속사용\n",
    "        for word in text:\n",
    "            counts[ord(word)-limit_a] += 1  # 문자 1개당 카운트 추가\n",
    "    # 빈도수는 값이 너무 퍼져있기때문에 0~1 사이로 정규화 시켜준다. => 학습효과가 뛰어나진다\n",
    "        total_count = sum(counts)\n",
    "        freq = list(map( lambda x:x/total_count , counts))\n",
    "    return lang, freq\n",
    "\n",
    "print(detect_trans_lang_freq(fName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train을 입력으로 넣으면 훈련용 데이터를 싹다 뽑아온다 (<-> test)\n",
    "def load_data(style='train'):\n",
    "    langs = []\n",
    "    freqs = []\n",
    "    file_list = glob.glob('./data/%s/*.txt' % style )\n",
    "    for file in file_list:\n",
    "        lang, freq = detect_trans_lang_freq(file)\n",
    "        langs.append(lang)\n",
    "        freqs.append(freq)\n",
    "    # 딕셔너리 정적 구성으로 최종 데이터 형태를 맞춰준다 => Dataframe 형태 고려\n",
    "    return {'labels':langs, 'freqs':freqs }\n",
    "load_data()['labels'][:2], load_data()['freqs'][:2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련용\n",
    "train_data = load_data()\n",
    "# 테스트용\n",
    "test_data = load_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 데이터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 데이터 모델링 및 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 시스템 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
