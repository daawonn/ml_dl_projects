{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손글씨 이미지 데이터 MNIST\n",
    "\n",
    "- 인코딩된 바이너리 데이터를 디코딩하여 처리하는 방식 확인\n",
    "- 지도학습\n",
    "- 학습용 데이터는 6만개, 테스트 데이터는 1만개\n",
    "- 결론 : \n",
    "    - 학습후 새로운 데이터를 입력시 판별\n",
    "    - 0 ~ 9 까지의 손글씨 이미지를 판별\n",
    "    - http://yann.lecun.com/exdb/mnist/index.html\n",
    "    - 데이터는 URL 을 직접 획득해서, 원하는 곳에 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 절차\n",
    "\n",
    "|No|단계|내용|\n",
    "|:---:|:---|:---|\n",
    "|1|연구목표|- 손글씨 이미지(0-9)를 학습시켜서 새로운 손글씨 이미지를 판별해 내는 머신러닝 모델을 구축<br>- 압축된 이미지를 압축해제<br>- 인코딩 된 데이터를 디코딩 처리<br>- 28X28로 구성된 픽셀 이미지데이터를 벡터화 처리<br>- 시스템 통합의 결과를 보고 연구목표를 설정해야하는데 시스템 통합을 생략하므로 이부분은 생략한다.|\n",
    "|2|데이터획득/수집|- http://yann.lecun.com/exdb/mnist 접속<br>- Web Scaraping을 통해서 데이터의 URL 획득 <br>- 지정된 위치에 다운로드 -> 압축해제|\n",
    "|3|데이터준비/전처리|- 디코딩(내부구조를 알 수 있는 인코딩 문서(MNIST Database) 필요)<br>- 엔디안(Endian)처리(추가적인 내용)<br>- 벡터화 처리|\n",
    "|4|데이터탐색/통찰/시각화분석|- skip (제공된 데이터가 명확함)|\n",
    "|5|데이터 모델링(머신러닝모델)|- 분류 알고리즘 사용<br>- 알고리즘선택 -> 훈련용,학습용 데이터로 나눔 -> 학습 -> 예측 ->평가|\n",
    "|6|시스템통합|- skip|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 데이터 획득/ 수집\n",
    "- 모듈준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as req\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootUrl = 'http://yann.lecun.com/exdb/mnist/'\n",
    "soup    = BeautifulSoup(req.urlopen(rootUrl), 'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train-images-idx3-ubyte.gz ,...등 총 4개의 url 획득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-images-idx3-ubyte.gz\n",
      "train-labels-idx1-ubyte.gz\n",
      "t10k-images-idx3-ubyte.gz\n",
      "t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 모든 요소 tt 중에 상위 4개만 링크\n",
    "for tt in soup.findAll('tt')[:4]:\n",
    "    # 링크 값이나 링크 문자열이나 현재 동일하기 때문에 문자열 획득으로 처리\n",
    "    # 링크 최종주소는 rootUrl + 링크 문자열을 더한것이다.\n",
    "    print(tt.a.string)  # 또는 print(tt.a.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train-images-idx3-ubyte.gz',\n",
       " 'train-labels-idx1-ubyte.gz',\n",
       " 't10k-images-idx3-ubyte.gz',\n",
       " 't10k-labels-idx1-ubyte.gz']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 링크 문자열을 리스트에 담은 이유는 반복 작업이 예상 되었기 때문이다.\n",
    "files = [ tt.a.string for tt in soup.findAll('tt')[:4] ] # 리스트내포\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다운로드 > 압축해제 <= 반복작업 총 4번 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 모듈\n",
    "import os, os.path, gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위치 선정(압축된 파일을 다운로드 할 위치)\n",
    "savePath = './data/mnist'\n",
    "# 해당 디렉토리가 없으면 만들도록 하기\n",
    "if not os.path.exists(savePath):  # 물리적으로 해당 경로가 없다.\n",
    "    os.makedirs(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595220216f404614a613f6714d56c658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소스 http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "대상 ./data/mnist/train-images-idx3-ubyte.gz\n",
      "소스 http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "대상 ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "소스 http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "대상 ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "소스 http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "대상 ./data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 저장\n",
    "# tqdm : 진행율을 보여주는 모듈\n",
    "from tqdm import tqdm_notebook\n",
    "for file in tqdm_notebook(files):\n",
    "    \n",
    "    print( '소스',rootUrl + file )\n",
    "    \n",
    "    # 저장위치 및 파일명\n",
    "    local_path = '%s/%s' % (savePath , file)\n",
    "    print( '대상',local_path )\n",
    "    \n",
    "    # 웹상에 존재하는 리소스를 로컬 디스크 상에 직접 저장\n",
    "    req.urlretrieve( rootUrl + file, local_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce44e50490f4bd1945d8987f3ca36f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/mnist/train-images-idx3-ubyte.gz\n",
      "./data/mnist/train-images-idx3-ubyte\n",
      "./data/mnist/train-labels-idx1-ubyte.gz\n",
      "./data/mnist/train-labels-idx1-ubyte\n",
      "./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "./data/mnist/t10k-images-idx3-ubyte\n",
      "./data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "./data/mnist/t10k-labels-idx1-ubyte\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 압축해제\n",
    "# 원본 : train-images-idx3-ubyte.gz\n",
    "# 해제 : train-images-idx3-ubyte  <= 원본 파일의 이름을 사용하겠다.\n",
    "for file in tqdm_notebook(files):\n",
    "    # 원본 파일의 경로\n",
    "    ori_gzip_file = '%s/%s' % (savePath , file)\n",
    "    print( ori_gzip_file )\n",
    "    # 압축 해제 파일의 경로 , 파일명은 다양한 방법으로 획득 가능\n",
    "    # 파일명에 반드시 확장자가 있을 필요는 없다\n",
    "    target_file ='%s/%s' % (savePath , file[:-3]) \n",
    "    print( target_file )\n",
    "    # 압축해제 \n",
    "    # gzip의 파일오픈 -> 읽기'rb' -> 쓰기\n",
    "    with gzip.open(ori_gzip_file, 'rb' ) as fg:\n",
    "        # 읽기 => 압축해제를 수행했다\n",
    "        tmp = fg.read()\n",
    "        # 쓰기 => 일반파일로 기록\n",
    "        with open( target_file, 'wb' ) as f:\n",
    "            f.write(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 데이터준비/전처리\n",
    "- 디코딩(내부구조를 알 수 있는 인코딩 문서(MNIST Database) 필요)\n",
    "- 엔디안(Endian)처리(TCP/IP 상에서 통신 수행시 중요)\n",
    "    - 컴퓨터 메모리와 같은 1차원 공간에 여러개의 연속된 데이터를 배열하는 방법\n",
    "    - 종류 : 바이트를 배치하는 오더(순서)를 앞에서부터 혹은 뒤에서부터 채우는가\n",
    "        - 0x12345678\n",
    "        - 빅 에디언\n",
    "            - 낮은(시작)주소에 상위 바이트부터 기록, Sparc / RISC CPU 계열\n",
    "            - 0x12 0x34 0x56 0x78  \n",
    "        - 리틀 에디언\n",
    "            - 낮은(시작) 주소에 하위 바이트부터 기록, Intel CPU 계열\n",
    "            - 0x78 0x56 0x34 0x12\n",
    "        - 위의 예는 정수값 (4 byte)을 예를 든것이고, 단지 값이 어떻게 기록됐는지만 이해하고, 그대로 값을 복원할 수 있으면 끝    \n",
    "- 벡터화 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LABEL FILE\n",
    "    - magic number : 4byte (32bit)  => 엔디안 체크\n",
    "    - LABEL 수 : 4byte              => 엔디안 체크\n",
    "    - LABEL 데이터 : 1byte ...      => 0 ~ 9 값\n",
    "    - 크기 = 4 + 4 + LABEL수 * 1byte = 4 + 4 + 60000 = 60008 byte\n",
    "    \n",
    "|offset|type|value|description|\n",
    "|:---:|:---|:---|:---|\n",
    "|0000|32 bit integer|0x00000801(2049)|magic number (MSB first)|\n",
    "|0004|32 bit integer|60000|number of items|\n",
    "|0008|unsigned byte|??|label|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IMAGE FILE\n",
    "    - magic number : 4byte (32bit)      => 엔디안 체크\n",
    "    - 손글씨 이미지 개수 : 4byte        => 엔디안 체크\n",
    "    - 가로크기(픽셀수) : 4byte          => 엔디안 체크\n",
    "    - 세로크기(픽셀수) : 4byte          => 엔디안 체크\n",
    "    - 픽셀값 한개 한개씩 : unsigned 1 byte(=8 bit) (0 ~ 2^8- 1 : 0~255(0xFF))\n",
    "    - 크기 \n",
    "    \n",
    "|offset|type|value|description|\n",
    "|:---:|:---|:---|:---|\n",
    "|0000|32 bit integer|0x00000801(2051)|magic number (MSB first)|\n",
    "|0004|32 bit integer|60000|number of images|\n",
    "|0008|32 bit integer|28|number of rows|   \n",
    "|0012|32 bit integer|28|number of columns| \n",
    "|0016|unsigned byte|??|pixel| \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원데이터의 구조를 \n",
    "import struct\n",
    "# struct : 바이너리 데이터를 빅/리틀 엔디안 방식으로 특정 바이트만큼 읽는 기능을 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2049 10000\n"
     ]
    }
   ],
   "source": [
    "# 테스트용 레이블 파일 처리\n",
    "# 바이너리 읽기 모드\n",
    "label_f = open('./data/mnist/t10k-labels-idx1-ubyte', 'rb')\n",
    "\n",
    "# 바이너리 데이터는 헤더부터 읽어서 데이터의 유효성이나 종류를 인지\n",
    "# MNIST 파일은 규격서에 high(빅) endian 으로 수치값을 기술했다고 확인했다.\n",
    "# label 파high(빅) endian일은 헤더가  4 + 4 + 8 byte 이다 (규격서 기준)\n",
    "# high(빅) endian => >\n",
    "# 4 -> I (i 의 대문자)\n",
    "magic_number, label_count = struct.unpack( '>II' , label_f.read(8) )\n",
    "\n",
    "# magic_number : 2049 레이블 파일이다\n",
    "# label_count  : 데이터의 개수 (레이블의 개수, 답의 개수)\n",
    "print(magic_number, label_count)\n",
    "\n",
    "# 닫기\n",
    "label_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2051 10000 28 28\n"
     ]
    }
   ],
   "source": [
    "# 테스트용 이미지파일 처리 - 위쪽 참고\n",
    "image_f = open('./data/mnist/t10k-images-idx3-ubyte', 'rb')\n",
    "\n",
    "magic_number2, label_count, row, col = struct.unpack( '>IIII' , image_f.read(16) )\n",
    "\n",
    "print(magic_number2, label_count, row, col)\n",
    "\n",
    "image_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2049 10000\n",
      "2051 10000 28 28\n",
      "이미지 파일의 크기 7840016 bytes\n"
     ]
    }
   ],
   "source": [
    "# 헤더 정보 추출\n",
    "# 헤더를 분석하면 바디를 알 수 있다\n",
    "label_f = open('./data/mnist/t10k-labels-idx1-ubyte', 'rb')\n",
    "image_f = open('./data/mnist/t10k-images-idx3-ubyte', 'rb')\n",
    "\n",
    "magic_number, label_count = struct.unpack( '>II' , label_f.read(8) )\n",
    "print(magic_number, label_count)\n",
    "\n",
    "magic_number2, image_count, row, col = struct.unpack( '>IIII' , image_f.read(16) )\n",
    "print(magic_number2, image_count, row, col)\n",
    "\n",
    "# 헤더크기 = 16 + 이미지데이터크기(28*28) * 이미지 총개수(10000)\n",
    "print('이미지 파일의 크기', 4 + 4 + 4 + 4 + 10000*28*28, 'bytes')\n",
    "\n",
    "# 헤더 정보를 기초로 반복 작업 수행 : 정답추출, 이미지 추출\n",
    "for idx in range(image_count) : # label_count 사용해도 동일\n",
    "    # 정답추출 : label_f를 통해서 1 byte 읽는다. \n",
    "    # 단, unsigned(부호없는,양수) byte -> 'B'\n",
    "    # 파일을 읽으면 읽은만큼 누적으로 커서(파일포인터) 위치가 이동한다 \n",
    "    label_tmp = struct.unpack( 'B', label_f.read(1) ) \n",
    "    #(7,) 이렇게 리턴 : 손글씨 숫자 7 -> 인덱싱을 통해서 값 획득\n",
    "    label = label_tmp[0]\n",
    "    # print(label) \n",
    "    \n",
    "    # 이미지 추출\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # 이미지 데이터의 벡터화 처리\n",
    "    break\n",
    "    pass\n",
    "\n",
    "label_f.close()\n",
    "image_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드, 주석이 길어지면 다음칸으로 옮김\n",
    "label_f = open('./data/mnist/t10k-labels-idx1-ubyte', 'rb')\n",
    "image_f = open('./data/mnist/t10k-images-idx3-ubyte', 'rb')\n",
    "\n",
    "magic_number, label_count = struct.unpack( '>II' , label_f.read(8) )\n",
    "magic_number2, image_count, row, col = struct.unpack( '>IIII' , image_f.read(16) )\n",
    "\n",
    "# 이미지 한개당 크기 28*28\n",
    "pixels = row*col # 28*28\n",
    "for idx in range(image_count) :\n",
    "    label_tmp = struct.unpack( 'B', label_f.read(1) ) \n",
    "    label = label_tmp[0]    \n",
    "    # 이미지 추출 ->  바이너리 데이터를 읽는다 -> 엔디안은 관계없음\n",
    "    binarryData = image_f.read(pixels)\n",
    "    # print(type(binarryData),len(binarryData) ,binarryData)\n",
    "    # 픽셀값 하나 하나를 문자열로 만들어서 리스트에 담는다\n",
    "    # 바이너리 값은 0~255의 문자열로 변경했다\n",
    "    strData = list( map( lambda x:str(x) , binarryData ) )\n",
    "    # print(strData)\n",
    "    \n",
    "    # csv에 한줄의 데이터로 기록 => 1 + 784 개를 기록 => 1개의 데이터를 표현 \n",
    "    # 구분자 ,  \n",
    "    \n",
    "    # pgm 파일로 dump 처리해서 확인 (데이터의 유효성 확인)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # 이미지 데이터의 벡터화 처리\n",
    "    break\n",
    "    pass\n",
    "\n",
    "label_f.close()\n",
    "image_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_f = open('./data/mnist/t10k-labels-idx1-ubyte', 'rb')\n",
    "image_f = open('./data/mnist/t10k-images-idx3-ubyte', 'rb')\n",
    "# csv 파일 오픈\n",
    "csv_f   = open( './data/mnist/t10k.csv', 'w', encoding='utf-8' )\n",
    "\n",
    "\n",
    "magic_number, label_count = struct.unpack( '>II' , label_f.read(8) )\n",
    "magic_number2, image_count, row, col = struct.unpack( '>IIII' , image_f.read(16) )\n",
    "\n",
    "pixels = row*col\n",
    "for idx in range(image_count) :\n",
    "    label_tmp = struct.unpack( 'B', label_f.read(1) ) \n",
    "    label = label_tmp[0]    \n",
    "    binarryData = image_f.read(pixels)\n",
    "    strData = list( map( lambda x:str(x) , binarryData ) )  \n",
    "    # csv에 한줄의 데이터로 기록 => 1 + 784 개를 기록 => 1개의 데이터를 표현 \n",
    "    # 구분자 : , \n",
    "    csv_f.write( str(label)+',' ) #답\n",
    "    csv_f.write(','.join( strData ) + '\\n') # \\n 줄바꿈 # 28*28의 손글씨 이미지 데이터\n",
    "    \n",
    "    # pgm 파일로 dump 처리해서 확인 (데이터의 유효성 확인)\n",
    "    # pgm 관련주소 : https://en.wikipedia.org/wiki/Netpbm#File_formats\n",
    "    if idx == 0: # 한번만 수행된다 (확인용으로 해봄)\n",
    "        with open('./data/mnist/%s.pgm' % label, 'w', encoding='utf-8') as f:\n",
    "            f.write( 'P2 28 28 255\\n' + ' '.join(strData) )\n",
    "        \n",
    "    \n",
    "    \n",
    "    # 이미지 데이터의 벡터화 처리\n",
    "    break\n",
    "    pass\n",
    "\n",
    "label_f.close()\n",
    "image_f.close()\n",
    "csv_f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_mnist_rawData( dataStyle='train',maxCount=0 ):\n",
    "    label_f = open('./data/mnist/%s-labels-idx1-ubyte' % dataStyle, 'rb')\n",
    "    image_f = open('./data/mnist/%s-images-idx3-ubyte' % dataStyle, 'rb')\n",
    "    csv_f   = open( './data/mnist/%s.csv' % dataStyle, 'w', encoding='utf-8' )\n",
    "\n",
    "    magic_number, label_count = struct.unpack( '>II' , label_f.read(8) )\n",
    "    magic_number2, image_count, row, col = struct.unpack( '>IIII' , image_f.read(16) )\n",
    "\n",
    "    if maxCount > image_count:\n",
    "        print('개수의 범위를 넘었습니다. 최소 %s 개 이내' % image_count)\n",
    "        return\n",
    "    elif maxCount == -1:\n",
    "        maxCount = image_count\n",
    "    elif maxCount < -1:\n",
    "        maxCount = image_count        \n",
    "        print('개수의 범위를 넘었습니다!!. 최소 %s 개 이내' % image_count)\n",
    "        return\n",
    "    \n",
    "    pixels = row*col\n",
    "    for idx in tqdm_notebook( range(maxCount) ) :\n",
    "        if idx >= maxCount:break\n",
    "        label_tmp = struct.unpack( 'B', label_f.read(1) ) \n",
    "        label = label_tmp[0]    \n",
    "        binarryData = image_f.read(pixels)\n",
    "        strData = list( map( lambda x:str(x) , binarryData ) )  \n",
    "\n",
    "        csv_f.write( str(label)+',' )\n",
    "        csv_f.write(','.join( strData ) + '\\n')\n",
    "\n",
    "\n",
    "    label_f.close()\n",
    "    image_f.close()\n",
    "    csv_f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a8efaf998e44b39083b31eb0391139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2100), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf24bdeb6ea418bb50f6d09ca2221e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=700), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 훈련용 데이터는 750개 테스트용은 250개를 준비한다\n",
    "decoding_mnist_rawData(maxCount=2100) # 훈련용\n",
    "decoding_mnist_rawData(dataStyle='t10k',maxCount=700) #테스트용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [M1] 데이터 품질 향상\n",
    "\n",
    "- 머신러닝 모델을 이용하여 예측시 정확도가 떨어지면 데이터의 품질, 양을 검토한다\n",
    "- 정확도 96% 목표로 머신러닝 모델을 개선한다\n",
    "    [사전조치]\n",
    "    - 양을 점차적으로 늘린다\n",
    "        - 데이터의 개수를 늘린다\n",
    "    - 품질을 향상시킨다\n",
    "        - 정규화 => 여러가지 사용후 교차 검증\n",
    "        - 차후에 적용가능한 내용 :PCA 같은 비지도 학습의 차원축소(피쳐의수를 줄인다: 독립변수의 갯수, 컬럼수) => 직교행렬\n",
    "    - 비율을 조정한다(훈련:테스트 = 75:25)\n",
    "    [모델개선조치]\n",
    "    - 알고리즘 교체\n",
    "    - 하이퍼파라미터 튜닝\n",
    "    - 파이프라인을 이용한 전처리기를 활용 (품질향상) 하여 향상\n",
    "    - 이런 교차 검증법을 활용하여 성능향상을 도모한다.\n",
    "    - 이런것들의 검증은 ROC 곡선, AUC값 등으로 확인할수도있고, 교차검증법의 결과로 확인가능하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터탐색/통찰/시각화분석\n",
    "\n",
    "- SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 함수를 만든다. load_csv( dataType='train' )\n",
    "# 현재 csv 파일은 : t10k.csv , train.csv\n",
    "# 입력 데이터 : csv 파일명\n",
    "# 출력 데이터 : { 'labels':[], 'images':[[ ]] }  labels => 답(0~9) ,images =>784개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv( dataType='train' ):\n",
    "    # 1. 파일명 생성\n",
    "    file_path = './data/mnist/%s.csv' % dataType\n",
    "    # 2. 데이터를 담을 그릇 준비\n",
    "    labels = list()\n",
    "    images = list()    \n",
    "    # 3.csv 파일 오픈\n",
    "    with open(file_path, 'r') as f:\n",
    "        # 4. 한줄씩 읽겠다. => 한줄이 데이터의 한 세트\n",
    "        for line in f:\n",
    "            # line 에 대해서 확인\n",
    "            # print( type(line) ,line )\n",
    "            tmp = line.split(',')\n",
    "            # 5. 데이터를 그릇에 추가 => 데이터는 원래대로 int 형으로 복원처리한다\n",
    "            labels.append( int(tmp[0]) )\n",
    "            images.append(list( map( lambda x:int(x) , tmp[1:] ) ))\n",
    "   \n",
    "    return { 'labels':labels, 'images':images } \n",
    "    \n",
    "train = load_csv()\n",
    "test  = load_csv('t10k')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255\n"
     ]
    }
   ],
   "source": [
    "print(min(train['images'][0]),max(train['images'][0]))\n",
    "# 값이 거리가 너무 멀다 -> 학습효과가 떨어진다 -> 0~1사이의 값으로 재배치 하는것이 합리적이다\n",
    "# 정규화처리 \n",
    "# 1번) 0: 0 이고 255:1 으로 만들어주기 <- minmax 스케일러\n",
    "# 2번) 값의 총개수 256 <- 범주형자료(분류형) 자료로 본다 \n",
    "# 픽셀데이터가 앞뒤 영향을 받는 연속적 성향을 가졌는가? 독립적인 성향을 가졌는가 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화처리 lambda x:int(x)/256 해줘서 minmax 스케일링\n",
    "def load_csv_ex( dataType='train' ):\n",
    "    file_path = './data/mnist/%s.csv' % dataType\n",
    "    labels = list()\n",
    "    images = list()    \n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            tmp = line.split(',')\n",
    "            labels.append( int(tmp[0]) )\n",
    "            images.append(list( map( lambda x:int(x)/256 , tmp[1:] ) ))\n",
    "   \n",
    "    return { 'labels':labels, 'images':images } \n",
    "    \n",
    "train = load_csv_ex()\n",
    "test  = load_csv_ex('t10k')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터모델링(머신러닝모델링)\n",
    "\n",
    "- 지도학습 데이터 이므로, 정확도를 통해서 평가를 1차로 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 모듈 가져오기\n",
    "from sklearn import svm, model_selection, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 알고리즘 생성\n",
    "SEED = 2020 # 난수 고정ㅇ을 통해서 svc가 내부적으로 사용하는 난수값의 패턴을 고정\n",
    "clf = svm.SVC(random_state=SEED)  # 난수고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 2100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 데이터 분류 (이미 위에서 완료)\n",
    "len(train['images']), len(train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=2020,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 학습\n",
    "clf.fit(train['images'], train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 예측\n",
    "predict = clf.predict(test['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. 성능평가\n",
    "metrics.accuracy_score(test['labels'], predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93        60\n",
      "           1       0.84      0.99      0.91        84\n",
      "           2       0.82      0.79      0.81        77\n",
      "           3       0.89      0.70      0.78        73\n",
      "           4       0.86      0.85      0.86        74\n",
      "           5       0.75      0.89      0.81        64\n",
      "           6       0.91      0.84      0.87        61\n",
      "           7       0.81      0.80      0.81        70\n",
      "           8       0.86      0.70      0.77        63\n",
      "           9       0.79      0.89      0.84        74\n",
      "\n",
      "    accuracy                           0.84       700\n",
      "   macro avg       0.85      0.84      0.84       700\n",
      "weighted avg       0.84      0.84      0.84       700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. 오차행렬(혼동행렬)을 이용한 평가\n",
    "clf_report = metrics.classification_report(test['labels'], predict)\n",
    "print(clf_report) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_minmax       = MinMaxScaler()\n",
    "y_train_norm2 = scaler_minmax.fit_transform(train['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(y_train_norm2, train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = clf.predict(scaler_minmax.fit_transform(test['images']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8832"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(test['labels'], predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler       = StandardScaler()\n",
    "y_train_norm = scaler.fit_transform(train['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=0,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(y_train_norm, train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = clf.predict(scaler.fit_transform(test['images']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9565"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(test['labels'], predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline( [\n",
    "    ('preprocessing', StandardScaler()),\n",
    "    ('classifier', SVC())\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'classifier': [SVC()],\n",
    "        'preprocessing': [StandardScaler()],\n",
    "        'classifier__C':[0.001,0.01,0.1,1,10,100],\n",
    "        'classifier__gamma':[0.001,0.01,0.1,1,10,100]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe,param_grid,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessing',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('classifier',\n",
       "                                        SVC(C=1.0, cache_size=200,\n",
       "                                            class_weight=None, coef0=0.0,\n",
       "                                            decision_function_shape='ovr',\n",
       "                                            degree=3, gamma='auto_deprecated',\n",
       "                                            kernel='rbf', max_iter=-1,\n",
       "                                            probability=False,\n",
       "                                            random_state=Non...\n",
       "                                             degree=3, gamma=0.001,\n",
       "                                             kernel='rbf', max_iter=-1,\n",
       "                                             probability=False,\n",
       "                                             random_state=None, shrinking=True,\n",
       "                                             tol=0.001, verbose=False)],\n",
       "                          'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          'preprocessing': [StandardScaler(copy=True,\n",
       "                                                           with_mean=True,\n",
       "                                                           with_std=True)]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(train['images'],train['labels'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8785714285714286"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8971428571428571"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(test['images'],test['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe31e8f251a04ed5a9758d8397c6ad89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb125931f154519a7c1b4459ab0ea80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6baf9a5d111e4d16a8bae36ce0aeef78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2357912cd346a096387864905d464d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f35e4ef5b64e63a95f5ac86ad886db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=22500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f043009ce62f4b1c847e691292fac3e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea43ebd41844a06b7163ba399e826e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02418d49fad94af38de0dccc3acaf04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 실험단계를 한개의 process로 정리\n",
    "\n",
    "# 75:25의 비율을 유지한다는 상황 => range(1,5)\n",
    "res_ac_scores = list()\n",
    "res_ac_reports = list()\n",
    "for cnt in range(1,5):\n",
    "    # 1.csv로 저장\n",
    "    decoding_mnist_rawData(maxCount=7500*cnt) # 훈련용\n",
    "    decoding_mnist_rawData(dataStyle='t10k',maxCount=2500*cnt) #테스트용\n",
    "\n",
    "    # 2.csv 로드\n",
    "    train = load_csv_ex()\n",
    "    test  = load_csv_ex('t10k') \n",
    "\n",
    "    # 3.모델 생성및 학습 예측 평가\n",
    "    SEED = 2020 # 난수 고정을 통해서 svc가 내부적으로 사용하는 난수값의 패턴을 고정\n",
    "    clf = svm.SVC(random_state=SEED)  \n",
    "    clf.fit(train['images'], train['labels'])\n",
    "    predict  = clf.predict(test['images'])\n",
    "    ac_score = metrics.accuracy_score(test['labels'], predict)\n",
    "    # 정확도 추가\n",
    "    res_ac_scores.append(ac_score)\n",
    "    # 오차행렬 추가\n",
    "    clf_report = metrics.classification_report(test['labels'], predict)\n",
    "    res_ac_reports.append(clf_report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8828, 0.901, 0.924, 0.9371]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ac_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.96      0.99      0.97      1135\n",
      "           2       0.94      0.92      0.93      1032\n",
      "           3       0.93      0.93      0.93      1010\n",
      "           4       0.92      0.95      0.93       982\n",
      "           5       0.92      0.91      0.91       892\n",
      "           6       0.94      0.96      0.95       958\n",
      "           7       0.95      0.92      0.94      1028\n",
      "           8       0.93      0.91      0.92       974\n",
      "           9       0.93      0.91      0.92      1009\n",
      "\n",
      "    accuracy                           0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(res_ac_reports[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
